{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805dfe42-143c-453c-bb0d-cc03efee95a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/potem/Carbonate/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# !pip install librosa # in colab, youâ€™ll need to install this\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e9ce1f-bd37-4c89-a5c7-15ab84453d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca31d010-b6ae-4229-8440-b0e2a0667a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d272b8-a202-4735-81be-bd64d521d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/nobackup/potem/timit-homework/tr'\n",
    "save_path = '/nobackup/potem/dl_data'\n",
    "val_path = '/nobackup/potem/timit-homework/v'\n",
    "test_path = '/nobackup/potem/timit-homework/te'\n",
    "\n",
    "def read_file(file_path):\n",
    "    s, sr = librosa.load(file_path, sr=None)\n",
    "    S = librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "    S_abs = np.abs(S)\n",
    "    \n",
    "    return torch.from_numpy(S.T), torch.from_numpy(S_abs.T), sr\n",
    "\n",
    "def load_files(path=path, types = ['trn','trx', 'trs']):\n",
    "    #noise, mixed, source\n",
    "\n",
    "    #Everything padded to 150\n",
    "    S_shape = (150, 513)\n",
    "    \n",
    "    for t in types:\n",
    "        temp_data = []\n",
    "        temp_data_abs = []\n",
    "        snr = []\n",
    "        for filename in glob.glob(f'{path}/{t}*.wav'):\n",
    "            S, S_abs, sr = read_file(filename)\n",
    "            \n",
    "            #pad = (padding_left, padding_right, padding_top, padding_bottom)\n",
    "            S = F.pad(S, \n",
    "                      pad=(0, 0, 0, S_shape[0] - S.shape[0]))\n",
    "            S_abs = F.pad(S_abs, \n",
    "                      pad=(0, 0, 0, S_shape[0] - S_abs.shape[0]))\n",
    "            \n",
    "#             S = S.narrow(0, 0, S_shape[0])\n",
    "#             S_abs = S_abs.narrow(0, 0, S_shape[0])\n",
    "#             print(sr)\n",
    "#             break\n",
    "\n",
    "            temp_data.append(S)\n",
    "            temp_data_abs.append(S_abs)\n",
    "            snr.append(torch.tensor(sr))\n",
    "            \n",
    "        temp_data = torch.stack(temp_data)\n",
    "        temp_data_abs = torch.stack(temp_data_abs)\n",
    "        snr = torch.stack(snr)\n",
    "       \n",
    "        torch.save(temp_data, f'{save_path}/{t}_tensor.pt') \n",
    "        torch.save(temp_data_abs, f'{save_path}/{t}_abs_tensor.pt') \n",
    "        torch.save(snr, f'{save_path}/{t}_snr_tensor.pt') \n",
    "        \n",
    "        \n",
    "# data = load_files(path)\n",
    "# data = load_files(test_path, ['te'])\n",
    "# data = load_files(val_path, ['vs', 'vx','vn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba033a45-b361-4fd4-a2a8-cbcb0fe30e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/N/slate/potem/dl_data/dl_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b903a40-d832-4864-ba77-8afd6b3188bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def IBM(source, noise):\n",
    "    return (source > noise).float()\n",
    "\n",
    "def get_data(path, types = ['vs', 'vx','vn']):\n",
    "    data = {}\n",
    "    for x in types:\n",
    "        data[x] = None\n",
    "        data[x + '_abs'] = None\n",
    "        \n",
    "    for x in types:\n",
    "        data[x] = torch.load(f'{path}/{x}_tensor.pt')\n",
    "        data[x + '_abs'] = torch.load(f'{path}/{x}_abs_tensor.pt')\n",
    "\n",
    "        snr_path = f'{path}/{x}_snr_tensor.pt'\n",
    "        \n",
    "        if os.path.isfile(snr_path):\n",
    "            data[x + '_snr'] = torch.load(snr_path)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "class PrepareData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(PrepareData, self).__init__()\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    \n",
    "def create_dataloader(x, y, batchsize):\n",
    "    data = PrepareData(x, y)\n",
    "   \n",
    "    return DataLoader(dataset=data, shuffle=False, \n",
    "                      batch_size=batchsize)\n",
    "    \n",
    "\n",
    "    \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, parameters):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        in_dim = parameters['in_dim']\n",
    "        out_dim = parameters['out_dim']\n",
    "        \n",
    "        self.type_init = parameters['type_init']\n",
    "        self.activation = parameters['activation']\n",
    "        self.dropout = parameters['dropout']\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=parameters['in_dim'],\n",
    "                            hidden_size=parameters['hidden_dim'],\n",
    "                            num_layers=parameters['num_layers'],\n",
    "                            batch_first=True,\n",
    "                            # dropout=parameters['dropout'],\n",
    "                           )\n",
    "        \n",
    "        if self.type_init == 'xavier':\n",
    "            for name, param in self.lstm.named_parameters():\n",
    "                if 'bias' in name:\n",
    "                     nn.init.constant(param, 0.0)\n",
    "                elif 'weight' in name:\n",
    "                     nn.init.xavier_normal(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lstm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def loss_snr(dataloader, loss_fn, model):\n",
    "    total_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sum_sq = torch.tensor(0.)\n",
    "        diff_sum = torch.tensor(0.)\n",
    "        total_loss = 0\n",
    "        \n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            sum_sq = sum_sq + (y * y).sum()\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred[0], y).item()\n",
    "            \n",
    "            total_loss = total_loss + loss\n",
    "            diff = torch.square(y - pred[0]).sum()\n",
    "            diff_sum = diff_sum + diff\n",
    "    \n",
    "    total_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    #adding 10**20 gave overflow when unpacking\n",
    "    snr = (10 * torch.log10((sum_sq / diff_sum))).item()\n",
    "           \n",
    "    return total_loss, snr\n",
    "    \n",
    "    \n",
    "    \n",
    "def train_model(model, dataloader, val_dataloader, \n",
    "          loss_fn, optimizer):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    " \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        \n",
    "#         print('X :', X.shape)\n",
    "#         print('y :', y.shape)\n",
    "#         print('pred :', pred[0].shape)\n",
    "#         break\n",
    "\n",
    "        loss = loss_fn(pred[0], y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_train, snr_train = loss_snr(dataloader, loss_fn, model)\n",
    "    loss_val, snr_val = loss_snr(val_dataloader, loss_fn, model)\n",
    " \n",
    "    return [loss_train, snr_train, loss_val, snr_val]\n",
    "\n",
    "def reconstruct(X, X_abs, S_abs, sr, filename):\n",
    "    S_recons = (X.numpy() / X_abs.numpy()) * S_abs\n",
    "    S_recons_sound = librosa.istft(S_recons, \n",
    "                                   hop_length=512, )\n",
    "    soundfile.write(filename, S_recons_sound, sr)\n",
    "\n",
    "def rnn_process(parameters):\n",
    "    train = get_data(path, ['trn','trx', 'trs'])\n",
    "    val = get_data(path, ['vs', 'vx','vn'])\n",
    "    # M_train = IBM(train['trs_abs'], train['trn_abs'])\n",
    "    # M_val = IBM(val['vs_abs'], val['vn_abs'])\n",
    "\n",
    "    train_dataloader = create_dataloader(train['trx_abs'], \n",
    "                                         train['trs_abs'], \n",
    "                                         parameters['batchsize'])\n",
    "    val_dataloader = create_dataloader(val['vx_abs'], \n",
    "                                      val['vs_abs'], \n",
    "                                      parameters['batchsize'])\n",
    "    \n",
    "    print('Train size :', len(train_dataloader))\n",
    "    print('Val size :', len(val_dataloader))\n",
    "    # print('Dataset ', \n",
    "\n",
    "    model = RNN(parameters)\n",
    "    filename = 'hw3_qns3_loss.pkl.gz'\n",
    "        \n",
    "    print(model)\n",
    "       \n",
    "    model.train()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer_adam = torch.optim.Adam(model.parameters(), \n",
    "                                      lr=parameters['lr_rate'])\n",
    "           \n",
    "    #train_loss, train_snr, val_loss, val_snr\n",
    "    all_loss = []\n",
    "    for t in range(parameters['epoch']):\n",
    "        loss = train_model(model, train_dataloader, \n",
    "                     val_dataloader, loss_fn, \n",
    "                     optimizer_adam)\n",
    "       \n",
    "        all_loss.append(loss)\n",
    "        \n",
    "        if t % 10 == 0:\n",
    "            print('Epoch :', t)\n",
    "            print('Train loss : ', loss[0])\n",
    "            print('Train snr : ', loss[1])\n",
    "            print('Val loss : ', loss[2])\n",
    "            print('Val snr : ', loss[3])\n",
    "\n",
    "    (pd.DataFrame(data=all_loss, \n",
    "                  columns=['train_loss', 'train_snr', 'val_loss', 'val_snr'])\n",
    "     .to_pickle(filename)\n",
    "    )\n",
    "        \n",
    "    torch.save(model.state_dict(), f'./hw_3_RNN.model')\n",
    "    \n",
    "    test = get_data(path, ['te'])\n",
    "    x_abs = test['te_abs']\n",
    "    x_original = test['te']\n",
    "    save_path = parameters['pred_path']\n",
    "    snr = test['te_snr']\n",
    "    \n",
    "    for index in range(len(test['te_abs'])):\n",
    "        T = x_original[index]\n",
    "        T_abs = x_abs[index]\n",
    "        T_unsq = torch.unsqueeze(T_abs, dim=0)\n",
    "        T_unsq = T_unsq.to(device)\n",
    "        \n",
    "        pred_t = model(T_unsq)\n",
    "        pred_t = torch.squeeze(pred_t[0], dim=0)\n",
    "        \n",
    "        pred_t_abs = pred_t.detach().cpu().data.numpy()\n",
    "\n",
    "        filename = f'{save_path}/{index}_pred.wav'\n",
    "        \n",
    "        reconstruct(T.T, T_abs.T, pred_t_abs.T, \n",
    "                    snr[index], filename)\n",
    "\n",
    "    \n",
    "rnn_parameters = {\n",
    "    \"in_dim\": 513,\n",
    "    \"out_dim\": 513,\n",
    "    \"hidden_dim\": 513,\n",
    "    \"conv1d_in_dim\": 118,\n",
    "    \"conv1d_out_dim\": 513,\n",
    "    \"batchsize\": 10,\n",
    "    \"dropout\": 0.01,\n",
    "    'num_layers': 1,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"type_init\": \"xavier\",\n",
    "    \"lr_rate\": 0.01,\n",
    "    \"epoch\": 100,\n",
    "    \"in_channel\": 1,\n",
    "    \"out_channel\": 1,\n",
    "    \"kernel_size\":10,\n",
    "    \"conv2d\":{\n",
    "        \"in_channel\": 1,\n",
    "        \"out_channel\": 3,\n",
    "        \"kernel_size\":(2, 2),\n",
    "        \"stride\": 3,\n",
    "        \"activation\": \"ReLU\",\n",
    "        \"type_init\": \"xavier\",\n",
    "        \"pool_kernel_size\": (2,2),\n",
    "        \"pool_stride\": 3,\n",
    "        \"in_dim\": 95,\n",
    "        \"out_dim\": 513,\n",
    "        \"dropout\": None,\n",
    "        \"2nd_kernel_size\": (2,2),\n",
    "        \"2nd_in_channel\": 3,\n",
    "        \"2nd_out_channel\":5\n",
    "    },\n",
    "    \"pred_path\": '/N/slate/potem/dl_data/dl_data/pred',\n",
    "    \"stride\": 2,\n",
    "    \"2d_stride\": 2,\n",
    "    \"pool_kernel_size\": 5,\n",
    "    \"pool_stride\": 1,\n",
    "}\n",
    "\n",
    "\n",
    "rnn_process(rnn_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a95c0-47e6-4f26-b3d0-b1efce2dbf38",
   "metadata": {},
   "source": [
    "### SNR values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5615f305-2e7d-47d1-a64e-f8c4fd23321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---- Hw3 : Qns 3 -------------------- \n",
      "\n",
      "    train_loss  train_snr  val_loss   val_snr\n",
      "15    0.016419   0.710551  0.016751  0.623522\n",
      "10    0.016528   0.681877  0.016766  0.619776\n",
      "6     0.016580   0.668182  0.016769  0.618804\n",
      "19    0.016357   0.726820  0.016771  0.618320\n",
      "12    0.016506   0.687663  0.016774  0.617706\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n---- Hw3 : Qns 3 -------------------- \\n')\n",
    "\n",
    "df = pd.read_pickle('hw3_qns3_loss.pkl.gz')\n",
    "df = df.sort_values(by=['val_snr'], ascending =False)\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
